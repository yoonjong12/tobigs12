{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes 과제\n",
    "\n",
    "#### 개요\n",
    "1. Multinomianl Naïve Bayes 예제로 데이터에서 Test값은 몇 % 확률로 어떤 클래스로 분류될까요? \n",
    "2. 실습코드 2번째 코드는 미완성의 코드입니다. 나이브 베이즈 클래시파이어를 구현 했지만 몇 가지 문제점을 가지고 있습니다.\n",
    " * 첫 째, 너무 많은 확률값을 가지고 있습니다. \n",
    " * 둘 째, 값이 0에 수렴할 수 있습니다. (어떤 기법을 적용해서 해결하면 좋을까요?)\n",
    "      \n",
    "   해당 문제를 코딩으로 구현하고 설명해주세요. e.g 너무 많은 확률 값을 가지고 있기에 00을 적용했습니다. \n",
    "   \n",
    "#### 데이터 출처\n",
    "\n",
    "1번 - 강의자님 제공\\\n",
    "2번 - German Credit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning texts \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beijing</th>\n",
       "      <th>chiense</th>\n",
       "      <th>chinese</th>\n",
       "      <th>japan</th>\n",
       "      <th>macao</th>\n",
       "      <th>shanghai</th>\n",
       "      <th>tokyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beijing  chiense  chinese  japan  macao  shanghai  tokyo\n",
       "0        1        1        1      0      0         0      0\n",
       "1        0        0        2      0      0         1      0\n",
       "2        0        0        1      0      1         0      0\n",
       "3        0        0        1      1      0         0      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [\"Chinese Chinese Chinese Tokyo Janpan\", \"?\"]\n",
    "  \n",
    "dataset = [[\"Chinese Beijing Chiense\", \"c\"], \n",
    "           [\"Chinese Chinese Shanghai\", \"c\"], \n",
    "           [\"Chinese Macao\", \"c\"],\n",
    "           [\"Tokyo Japan Chinese\", \"j\"]] \n",
    "              \n",
    "dataset = pd.DataFrame(dataset) \n",
    "dataset.columns = [\"Text\", \"Class\"]\n",
    "\n",
    "cv = CountVectorizer() \n",
    "y = dataset['Class'].values \n",
    "X = cv.fit_transform(dataset.Text)\n",
    "feature_df = pd.DataFrame(X.toarray(), columns=cv.get_feature_names())\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dataset에서 Text, Class로 구분을 해줍니다\n",
    "* CountVectorizer로 전처리를 해줍니다. 단어들을 토큰화시켜서 나이브 베이즈 분류를 해주기위해서는 데이터를 BoW로 만들어줄 필요가 있습니다.\n",
    "* 텍스트를 자동으로 BoW로 만드는 CountVectorizer를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다항분포 나이브 베이즈 모델 클래스를 사용합니다. 파라밍터의 alpha=1.0은 라플라스 스무딩이 사용되었음을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beijing</th>\n",
       "      <th>chiense</th>\n",
       "      <th>chinese</th>\n",
       "      <th>japan</th>\n",
       "      <th>macao</th>\n",
       "      <th>shanghai</th>\n",
       "      <th>tokyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beijing  chiense  chinese  japan  macao  shanghai  tokyo\n",
       "0        0        0        3      0      0         0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"Chinese Chinese Chinese Tokyo Janpan\"]\n",
    "test_cv = cv.transform(test)\n",
    "feature_df = pd.DataFrame(test_cv.toarray(), columns=cv.get_feature_names())\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 = c, 확률 = 0.8223684210526319\n"
     ]
    }
   ],
   "source": [
    "predicted = mod.predict(test_cv) \n",
    "prob = np.max(mod.predict_proba(test_cv))\n",
    "print(f'예측 = {predicted[0]}, 확률 = {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test 문장을 기존의 cv에 transform해주고 확인을 해보니 토큰화가 잘 되었습니다.\n",
    "* mod에 test문장을 인자로 넣어주어 모델의 출력값인 class를 predicted에 넣어줍니다.\n",
    "* predict_proba로 확률값 또한 받아주는데, 각 클래스 별 확률이 numpy array로 반환됩니다. 따라서 제일 높은 값을 max로 받아와서 prob에 넣어줍니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제2\n",
    "\n",
    "* German Credit Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>History</th>\n",
       "      <th>CoApplicant</th>\n",
       "      <th>Accommodation</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>paid</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>paid</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>rent</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>arrears</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  History CoApplicant Accommodation  Fraud\n",
       "0   1  current        none           own   True\n",
       "1   2     paid        none           own  False\n",
       "2   3     paid        none           own  False\n",
       "3   4     paid   guarantor          rent   True\n",
       "4   5  arrears        none           own  False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = '../data/fraud.csv'\n",
    "df = pd.read_csv(data_url, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False,  True, False, False, False,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"ID\"] \n",
    "Y_data = df.pop(\"Fraud\")\n",
    "Y_data = Y_data.values\n",
    "Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ID는 분석에 의미가 없으니 제거, 타겟 데이터인 Fraud값을 따로 떼어서 저장합니다.\n",
    "* 범주형 변수들을 더미로 만들어주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>History_arrears</th>\n",
       "      <th>History_current</th>\n",
       "      <th>History_none</th>\n",
       "      <th>History_paid</th>\n",
       "      <th>CoApplicant_coapplicant</th>\n",
       "      <th>CoApplicant_guarantor</th>\n",
       "      <th>CoApplicant_none</th>\n",
       "      <th>Accommodation_free</th>\n",
       "      <th>Accommodation_own</th>\n",
       "      <th>Accommodation_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   History_arrears  History_current  History_none  History_paid  \\\n",
       "0                0                1             0             0   \n",
       "1                0                0             0             1   \n",
       "2                0                0             0             1   \n",
       "3                0                0             0             1   \n",
       "4                1                0             0             0   \n",
       "\n",
       "   CoApplicant_coapplicant  CoApplicant_guarantor  CoApplicant_none  \\\n",
       "0                        0                      0                 1   \n",
       "1                        0                      0                 1   \n",
       "2                        0                      0                 1   \n",
       "3                        0                      1                 0   \n",
       "4                        0                      0                 1   \n",
       "\n",
       "   Accommodation_free  Accommodation_own  Accommodation_rent  \n",
       "0                   0                  1                   0  \n",
       "1                   0                  1                   0  \n",
       "2                   0                  1                   0  \n",
       "3                   0                  0                   1  \n",
       "4                   0                  1                   0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = pd.get_dummies(df)\n",
    "x_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array = x_df.values\n",
    "x_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. as_matrix()함수를 통해 우리가 하고자 하는 것은 무엇일까요?\n",
    "* 나이브 베이즈를 통해 as_matrix로 만든 더미와 타겟 데이터들을 가지고 분류를 하려고 합니다. \n",
    "\n",
    "* pandas DataFrame 자체로는 모델에 넣을 수 없기 때문에 numpy 타입으로 바꿔줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(x_array, Y_data)\n",
    "print(np.exp(model.class_log_prior_))\n",
    "\n",
    "# 2) 손코딩\n",
    "P_Y_True = sum(Y_data) / len(Y_data) # True 개수 / label set length \n",
    "P_Y_False = 1 - P_Y_True # False 개수 / label set length\n",
    "P_Y_False, P_Y_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 0,  3,  5,  9, 11, 12], dtype=int64),),\n",
       " (array([ 1,  2,  4,  6,  7,  8, 10, 13, 14, 15, 16, 17, 18, 19],\n",
       "        dtype=int64),))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 Boolean 값에 해당하는 index 가져오기 \n",
    "ix_Y_True = np.where(Y_data)\n",
    "ix_Y_False = np.where(Y_data == False)\n",
    "\n",
    "ix_Y_True, ix_Y_False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05555556 0.16666667 0.05555556 0.05555556 0.         0.05555556\n",
      " 0.27777778 0.         0.22222222 0.11111111]\n",
      "[0.14285714 0.0952381  0.         0.0952381  0.04761905 0.\n",
      " 0.28571429 0.02380952 0.26190476 0.04761905]\n"
     ]
    }
   ],
   "source": [
    "# P(Xi|Yc) \n",
    "# p_x_y_true = (x_array[ix_Y_True].sum(axis=0) / sum(Y_data==True))  # Q.뒤에 sum(Y_data == True) 필요한가요? 각 xi에 따른 확률 값도 확인 할 수 있지 않나요?\n",
    "# p_x_y_true = ( model.feature_count_[1] / sum(Y_data))\n",
    "# 뒤에 trainset에서 각 클래스 빈도를 넣음 sum(y_c) \n",
    "\n",
    "p_x_y_true = (x_array[ix_Y_True].sum(axis=0) / sum(Y_data==True))\n",
    "p_x_y_false = (x_array[ix_Y_False].sum(axis=0) / sum(Y_data==False))\n",
    "\n",
    "\n",
    "# productP(X|Yc) with sklearn\n",
    "# 뒤에 각 클래스 별 feature들의 빈도의 sum을 넣음\n",
    "# 수업자료에 sum of all term freq in y_c라고 되어있는 것으로 봐선 이쪽이 맞지 않나?\n",
    "\n",
    "fc = model.feature_count_\n",
    "product_ = fc / fc.sum(axis=1)[:,None] # == fc / np.repeat(fc.sum(axis=1)[:, np.newaxis], 10, axis=1)\n",
    "p_x_y_true = product_[1]\n",
    "p_x_y_false = product_[0]\n",
    "\n",
    "print(p_x_y_true)\n",
    "print(p_x_y_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 클래스와 특성의 값이 훈련 데이터에서 발생 하지 않는 경우에는, 빈도수 기반의 확률 추정치는 0이 됩니다. 이것은 이 추정치가 곱해질 때 다른 확률의 모든 정보를 없앨 수 있기 때문에 문제가 될 수 있습니다. 따라서, 대부분의 확률 추정에서는 그 값이 0이 되지 않도록 정규화 시켜주는데, 가짜 수(pseudocount) 1을 보정값을 주는 방법을 라플라스 정규화(Laplace smoothing)라고 불립니다.\n",
    "\n",
    "* 간단하게 확률 값을 모두 곱하는 방식은 0에 가까워지면서 언더플로 문제가 발생합니다. 따라서 log를 취해주어 바꾸어 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13461538 0.09615385 0.01923077 0.09615385 0.05769231 0.01923077\n",
      "  0.25       0.03846154 0.23076923 0.05769231]\n",
      " [0.07142857 0.14285714 0.07142857 0.07142857 0.03571429 0.07142857\n",
      "  0.21428571 0.03571429 0.17857143 0.10714286]]\n",
      "[0.13461538 0.09615385 0.01923077 0.09615385 0.05769231 0.01923077\n",
      " 0.25       0.03846154 0.23076923 0.05769231]\n",
      "[0.07142857 0.14285714 0.07142857 0.07142857 0.03571429 0.07142857\n",
      " 0.21428571 0.03571429 0.17857143 0.10714286]\n"
     ]
    }
   ],
   "source": [
    "# 1) sklearn\n",
    "theta = np.exp(model.feature_log_prob_)\n",
    "print(theta)\n",
    "\n",
    "\n",
    "# model.alpha = 1.0\n",
    "theta = (fc + model.alpha) / (fc.sum(axis=1)[:,None] + model.alpha * x_array.shape[1])\n",
    "p_x_y_true = theta[1]\n",
    "p_x_y_false = theta[0]\n",
    "\n",
    "print(p_x_y_false)\n",
    "print(p_x_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.1382820417027695, -1.4175469046239952)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log(P(Fraud|features)) = log(P(History_arrears|Fraud))+log(P(CoApplicant_coapplicant|Fraud)+…+log(P(Fraud))\n",
    "x_test = [0,1,0,0,0,1,0, 0,1,0]\n",
    "\n",
    "p_y_true_test = np.log(P_Y_True) + np.log(p_x_y_true.dot(x_test))\n",
    "p_y_false_test = np.log(P_Y_False) + np.log(p_x_y_false.dot(x_test))\n",
    "\n",
    "p_y_true_test, p_y_false_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 테스트 데이터를 넣어보니 거짓으로 구분했습니다.\n",
    "\n",
    "## ref\n",
    "* https://datascienceschool.net/view-notebook/c19b48e3c7b048668f2bb0a113bd25f7/\n",
    "* https://ko.wikipedia.org/wiki/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98\n",
    "* https://bcho.tistory.com/1010\n",
    "* https://kenzotakahashi.github.io/naive-bayes-from-scratch-in-python.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
